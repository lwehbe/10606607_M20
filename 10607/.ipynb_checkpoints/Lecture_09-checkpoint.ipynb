{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Graphs\n",
    "\n",
    "Lecture based on [Michael Jordan's Graphical Models lecture notes sections 1-3.1](https://www.cs.cmu.edu/~aarti/Class/10701/readings/graphical_model_Jordan.pdf) and [Matt Gormley's slides on factor graphs](http://www.cs.cmu.edu/~mgormley/courses/606-607-f18/slides607/lecture10-factorgraph.pdf) and [variable elimination](http://www.cs.cmu.edu/~mgormley/courses/606-607-f18/slides607/lecture11-inference.pdf)\n",
    "\n",
    "Graphical models are families of probability distributions that are defined using a graph. Variables in the distribution correspond to nodes in the graph. The joint probability distribution over all variables is a product of smaller functions of smaller groups of variables. There are multiple ways in which these functions are defined:\n",
    "- Bayes nets are directed acyclic graphs that encode relationships between variables. Each variable $v$ is associated with the conditional distribution of $v$ given the set of its parents $\\pi_v$, and the joint probability dsitribution is the product of all these conditional distributions:\n",
    "$$p(x_1,x_2...x_n) = \\prod_{v=1}^n p(x_v|x_{\\pi_v})$$\n",
    "- Factor Graphs are undirected models in which each clique of variables $C_i$ is associated with a factor $f_i(x_{C_i})$. The joint probability is obtained by taking the normalized product of the potential functions:\n",
    "$$p(x_1,x_2...x_n) = \\frac{1}{Z}\\prod_{i\\in\\mathcal{I}}f_i(x_{C_i})$$.\n",
    "Z is a normalization factor, obtained by integrating or summing over all combinations of values of the $x_1,x_2...x_n$. Factor graphs are bi-partite graphs with one set of nodes corresponding to variables and another one to factors. There is an edge between $f_i$ and the node corresponding to $X_v$ if and only if $X_v$ is in clique $C_i$.\n",
    "\n",
    "Factor graphs are more common in areas where there is no clear causal relationship between variables. You can convert between bayes nets and factor graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginalization and inference\n",
    "\n",
    "One common use of factor graphs is to determine marginal or conditional probability. For example, given some of the variables, we might want to find our the conditional probability of another variable.\n",
    "\n",
    "#### P and NP-Hard\n",
    "The class P consist of algorithms that can run in polynomial time. The class NP refers to problems for which a correct answer can be verified in polynomial time.\n",
    "A problem is NP-hard if other NP problems can be solved if that problem is solved using a O(1) oracle.\n",
    "A problem is NP-Complete if it belongs to both NP and NP-Hard.\n",
    "\n",
    "- Marginal inference (in P) consist in finding marginals of variables and cliques (while optionally conditioning on other variables)\n",
    "- Partition function computation (in P) consist in computing the value of Z\n",
    "- MAP inference (NP-Hard) consist in computing the variable assignmeng with highest probability.\n",
    "\n",
    "#### How to marginalize? Brute force solution\n",
    "\n",
    "Compute the entire table comprising of all possible settings of the variables. If we have $n$ variables with $k$ values each, then the table will have $k^n$ entries!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Elimination algorithm for marginal inference\n",
    "\n",
    "Use the factorization of $p(x)$ to marginalize over variables while computing intermediate factors that are much smaller than $k^n$.\n",
    "\n",
    "Brute force is $O(k^n)$, whereas variable elimination is $O(nk^r)$ where $r$ is the number of variables participating in the largest intermediate factor. \n",
    "\n",
    "#### How to choose the variable elimination order:\n",
    "The order might have a big effect on efficiency, and it turns out that choosing the optimal order is NP-hard. One can use multiple heuristics, such as always choosing a variable with the fewest neighbors, or the one with the smallest size of factor to be added to the graph. Another technique is to run BFS on the graph and then use the opposite order.\n",
    "\n",
    "##### Algorithm 1: Variable Elimination algorithm for marginal inference\n",
    "- Input: the factor graph and the query variable\n",
    "- Output: the marginal distribution for the query variable\n",
    "    1. Run a breadth-first-search starting at the query variable to obtain an ordering of the\n",
    "variable nodes\n",
    "    2. Reverse that ordering\n",
    "    3. Eliminate each variable in the reversed ordering using Algorithm 2\n",
    "    \n",
    "##### Algorithm 1-modified: Variable Elimination algorithm for marginal inference\n",
    "- Input: the factor graph and the query variable\n",
    "- Output: the marginal distribution for the query variable\n",
    "    1. Obtain an ordering for the variables.\n",
    "    2. Eliminate each variable in the reversed ordering using Algorithm 2\n",
    "\n",
    "##### Algorithm 2: Eliminate One Variable\n",
    "- Input: the variable to be eliminated\n",
    "- Output: new factor graph with the variable marginalized out\n",
    "    1. Find the input variable and its neighboring factors -- call this set the eliminated set\n",
    "    2. Replace the eliminated set with a new factor\n",
    "        1. The neighbors of the new factor should be all the neighbors of all the factors in the eliminated\n",
    "set\n",
    "        2. The new factor should assign a score to each possible assignment of its neighboring variables\n",
    "        3. Said score should be identical to the product of the factors it is replacing, summing over the\n",
    "eliminated variable\n",
    "\n",
    "##### Algorithm 3: Variable Elimination for the Partition Function (Z)\n",
    "- Input: the factor graph\n",
    "- Output: the partition function\n",
    "    1. Run a breadth-first-search starting at an arbitrary variable to obtain an ordering of the\n",
    "variable nodes\n",
    "    2. Eliminate each variable in the ordering using Algorithm 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
